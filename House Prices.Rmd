---
title: "House Prices - Linear Model"
output: html_notebook
---

> **Index**

1. [Data Loading](#data-loading)
2. [Data Understanding](#data-understanding)
3. [Tidyr: Gather, Spread](#library-tidyr)


This example will be around a [Kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) where we want to **predict the price of a house** depending on its caracteristics.

### Data Loading

Data comes in 2 files:

1. *train.csv* The training set

2. *test.csv* The final evaluation set.

Our file contains 81 columns and 1460 records
```{r, warning=FALSE, message=FALSE}
# Set environment
source("utils.R")
set_environment("/Users/deliadelaguila/Documents/GitHub/Catalog")

# Load Data
housing <- read_csv("./Data/House Pricing/data_train.csv", na= "")
head(housing)
```


### Data Understanding
Let's check each one of our 81 variables. 

> SalePrice

The property's sale price in dollars. This is the target variable that we are trying to predict. A numeric variable with normal distribution skewed to the right around 140,000 as mode

```{r}
get_mode(housing$SalePrice)
summary(housing$SalePrice)
```

```{r, message=FALSE}
viz_hist(housing, "SalePrice")
```


> MSSubClass, MSZoning, LotFrontage, LotArea, Street, Alley

- **MSSubClass:** The building class. Factor variable with 20 and 60 as most popular values

- **MSZoning:** The general zoning classification. Factor variables with RL as mode

- **LotFrontage:** Linear feet of street connected to property. Numeric variable with teh first 3 standard deviations between 21 and 80, it has some outliers and 259 NAs values.

- **LotArea:** Lot size in square feet. Numeric variables with big range

- **Street:** Type of road access. Factor variable with Pave for almost all records, variable not consider for prediction

- **Alley:** Type of alley access. Factor variable with many Not Available values, variable not consider for prediction.

- **LotShape:** General shape of property. Factor variable with most common values as Reg and IR1

```{r, message=FALSE}
housing_col <- colnames(housing)
housing %>% select(housing_col[2:5]) %>% summary()
```

```{r, message=FALSE, warning=FALSE}
housing$MSSubClass <- as.factor(housing$MSSubClass)
p1 <- viz_bar(housing, housing_col[2])

housing$MSZoning <- as.factor(housing$MSZoning)
p2 <- viz_bar(housing, housing_col[3])

housing$LotFrontage <- as.numeric(housing$LotFrontage)
p3 <- viz_density(housing, housing_col[4])

housing$LotArea <- as.numeric(housing$LotArea)
p4 <- viz_density(housing, housing_col[5])

grid.arrange(p1, p2, p3, p4, nrow = 2)
       
```


LandSlope: Slope of property
Neighborhood: Physical locations within Ames city limits
Condition1: Proximity to main road or railroad
Condition2: Proximity to main road or railroad (if a second is present)
BldgType: Type of dwelling
HouseStyle: Style of dwelling
OverallQual: Overall material and finish quality
OverallCond: Overall condition rating
YearBuilt: Original construction date
YearRemodAdd: Remodel date
RoofStyle: Type of roof
RoofMatl: Roof material
Exterior1st: Exterior covering on house
Exterior2nd: Exterior covering on house (if more than one material)
MasVnrType: Masonry veneer type
MasVnrArea: Masonry veneer area in square feet
ExterQual: Exterior material quality
ExterCond: Present condition of the material on the exterior
Foundation: Type of foundation
BsmtQual: Height of the basement
BsmtCond: General condition of the basement
BsmtExposure: Walkout or garden level basement walls
BsmtFinType1: Quality of basement finished area
BsmtFinSF1: Type 1 finished square feet
BsmtFinType2: Quality of second finished area (if present)
BsmtFinSF2: Type 2 finished square feet
BsmtUnfSF: Unfinished square feet of basement area
TotalBsmtSF: Total square feet of basement area
Heating: Type of heating
HeatingQC: Heating quality and condition
CentralAir: Central air conditioning
Electrical: Electrical system
1stFlrSF: First Floor square feet
2ndFlrSF: Second floor square feet
LowQualFinSF: Low quality finished square feet (all floors)
GrLivArea: Above grade (ground) living area square feet
BsmtFullBath: Basement full bathrooms
BsmtHalfBath: Basement half bathrooms
FullBath: Full bathrooms above grade
HalfBath: Half baths above grade
Bedroom: Number of bedrooms above basement level
Kitchen: Number of kitchens
KitchenQual: Kitchen quality
TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)
Functional: Home functionality rating
Fireplaces: Number of fireplaces
FireplaceQu: Fireplace quality
GarageType: Garage location
GarageYrBlt: Year garage was built
GarageFinish: Interior finish of the garage
GarageCars: Size of garage in car capacity
GarageArea: Size of garage in square feet
GarageQual: Garage quality
GarageCond: Garage condition
PavedDrive: Paved driveway
WoodDeckSF: Wood deck area in square feet
OpenPorchSF: Open porch area in square feet
EnclosedPorch: Enclosed porch area in square feet
3SsnPorch: Three season porch area in square feet
ScreenPorch: Screen porch area in square feet
PoolArea: Pool area in square feet
PoolQC: Pool quality
Fence: Fence quality
MiscFeature: Miscellaneous feature not covered in other categories
MiscVal: $Value of miscellaneous feature
MoSold: Month Sold
YrSold: Year Sold
SaleType: Type of sale
SaleCondition: Condition of sale




```{r}
datos <- housing %>% select(-GarageYrBlt, -LotFrontage, -MasVnrArea, -GarageYrBlt, -MoSold, -PoolQC)
datos$MSSubClass <- factor(datos$MSSubClass)
```


### Preprocesamiento 

Necesitamos hacer varios pasos de limpieza y preprocesamiento de datos.
Aqu?? solo haremos una limpieza y transformaci??n parcial para prop??sitos de
nuestro ejemplo.

En primer lugar, nota que muchas de estas variables son categ??ricas. En los casos donde hay
datos no disponibles (NA), estas se cuentan como una categor??a m??s, por ejemplo:

```{r}
table(datos$Alley)
```

En este caso, la categor??a NA indica que la casa no tiene acceso por callej??n. Igual que en el ejemplo
del Titanic, convertimos estas variables con *dummy coding*, o *one hot encoding*.

Podemos usar la funci??n *model.matrix* para hacer este preprocesamiento:

```{r}
x_datos <- model.matrix(SalePrice ~ ., datos %>% select(-Id))
x_datos <- x_datos[, -1] # quitamos columna de unos
y <- datos$SalePrice
```

Por ejemplo, la variable categ??rica *Alley* (con 3 niveles) corresponde ahora
a dos columnas de variables binarias:

```{r}
x_datos[c(20,21,22,31), c('AlleyNA','AlleyPave')]
```

que puedes comparar con la variable original

```{r}
datos[c(20,21,22,31), "Alley"]
```

Otro ejemplo es la variable *MSZoning*, cuyas categor??as son:

```{r}
table(datos$MSZoning)
```

y corresponde a las nuevas variables

```{r}
x_datos[1:10, 15:18]
```

Aqu?? mostramos las variables que usaremos para nuestros modelos:

```{r}
colnames(x_datos)
```

Finalmente, la variable que queremos predecir es
*SalePrice*:

```{r}
qplot((datos$SalePrice))
```

**Nota: veremos m??s adelante m??s pasos de preprocesamiento para
mejorar considerablemente el modelo que obtenemos abajo.**

### Regresi??n ridge

Separamos un conjunto de entrenamiento y uno de prueba (1/2 aproximadamente)

```{r}
set.seed(9911)
indices_entrena <- sample(1:nrow(x_datos), 700)
x_ent <- x_datos[indices_entrena, -1] # primera columna es de 1's, la quitamos
y_ent <- y[indices_entrena] / 1000 # miles de d??lares
x_pr <- x_datos[-indices_entrena, -1]
y_pr <- y[-indices_entrena] / 1000 #miles de d??lares
```

1. Utiliza la funci??n glmnet para ajustar modelos lineales para 
valores de regularizaci??n. Utiliza la siguiente sucesi??n de
valores $\lambda$ de regularizaci??n ridge:

```{r}
lambda <- exp(seq(-10, 10, 1))
lambda
```

```{r}
# completa los par??metros que faltan para ajustar los modelos:
mod_ridge <- glmnet(y = y_ent, x = x_ent, alpha = 0, family = "gaussian", 
                lambda = lambda)
```

Grafica la traza de los coeficientes:

```{r}
plot(mod_ridge, xvar= "lambda")
```

- ??Qu?? pasa con los coeficientes cuando aumenta el valor de lambda? - Tienden a cero
- ??Todos los coeficientes se acercan siempre al valor 0 cuando aumentamos
la regularizaci??n? - Haya algunos que aumentan ligeramente pero despues convergen
- ??Por qu?? parece ser que los coeficientes tienen valores casi constantes 
para valores suficientemente bajos de lambda? - 

2. Selecciona el valor de regularizaci??n usando validaci??n
cruzada con la funci??n *cv.glmnet*:

```{r}
# completa los par??metros que faltan:
cv_mod_1 <- cv.glmnet(y = y_ent, x = x_ent, alpha = 0, family = "gaussian",
                      lambda = lambda, nfolds = 10)
plot(cv_mod_1)
```

??Qu?? valores de la regularizaci??n dan los errores m??s bajos 
(seg??n la estimaci??n de validaci??n cruzada?)

```{r}
cv_mod_1$lambda.min
max(cv_mod_1$lambda)

cv_mod_1$lambda.1se
```


3. Selecciona un modelo con baja regularizaci??n, con el valor ??ptimo
seg??n validaci??n cruzada, y otro con mucha regularizaci??n (utiliza las lambdas
mostradas abajo).
Eval??a el
error de predicci??n (ra??z de error cuadr??tico media) 
seg??n la muestra de prueba que separamos arriba:

```{r}
# rellena tres valores, uno con muy baja regularizaci??n , uno con regularizaci??n
#??ptima seg??n validaci??n cruzada, y otro con demasiada regularizaci??n:
lambda_pred <- c(lambda[1] , cv_mod_1$lambda.min, max(cv_mod_1$lambda))
lambda_pred
```

Calcula errores de prueba

```{r}
preds_1 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[1])
preds_2 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[2])
preds_3 <- predict(mod_ridge, newx = x_pr, s = lambda_pred[3])
sqrt(mean((preds_1 - y_pr)^2))
sqrt(mean((preds_2 - y_pr)^2))
sqrt(mean((preds_3 - y_pr)^2))
#
#
```

- ??Qu?? modelo tiene el error m??s bajo de prueba? ??Por qu?? esperar??as esto?


Grafica predicciones del modelo con menor error contra los valores observados

```{r}
# Haz tu gr??fica aqu??
plot(preds_1,y_pr)

```


4. Compara los coeficientes del modelo menos regularizado con el de
regularizaci??n ??ptima


```{r}
coefs_reg_baja <- predict(mod_ridge, 
                          s = lambda_pred[1], type= "coefficients")
coefs_reg_baja <- coefs_reg_baja[-1,1] # tomamos la primera columna y quitamos intercept
# rellena aqu??
coefs_reg_opt <- predict(mod_ridge, 
                          s = lambda_pred[3], type= "coefficients")
coefs_reg_opt <- coefs_reg_opt[-1,1] 
    
# ahora grafica estos coeficientes en una gr??fica x-y:
plot(coefs_reg_opt,coefs_reg_baja)


```

```{r}
qplot(coefs_reg_opt, coefs_reg_baja) + 
  xlab('Coeficientes Optimos') + 
  ylab('Coeficientes estimados') +
  geom_abline(intercept=0, slope =1) +
  xlim(c(-0.5,0.5))+ ylim(c(-0.5,0.5))
```


- ??Qu?? puedes decir acerca de la dispersi??n de los coeficientes del modelo
con baja regularizaci??n en comparaci??n al de regularizaci??n media? ??Cu??l
es el rango de los coeficientes del modelo con baja regularizaci??n? 

5. Compara algunos coeficientes de dos modelos, el de regularizaci??n baja con
uno de regularizaci??n ??ptima seg??n validaci??n cruzada

Por ejemplo, compara los coeficientes relacionados con el garage (tipo, terminados,
Calidad, Condici??n, coches y ??rea):

```{r}
nombres <- rownames(coefs_reg_baja)
coef_garage_baja <- coefs_reg_baja[, 1][str_detect(nombres, "Garage")]
coef_garage_baja
```

- ??Qu?? efecto puede tener esta variable en tus predicciones? Considera que el tama??o
de los coeficientes est?? en miles de d??lares,
- ??Cu??l es el valor mediano de las casas en el conjunto de entrenamiento (y)? ??Los
efectos del inciso anterior te parecen razonables?


Repite para regularizaci??n ??ptima seg??n validaci??n cruzada:

```{r}
# calcula para los coeficientes del modelo m??s regularizado

```

- ??Qu?? efecto puede tener esta variable en tus predicciones? Considera que el tama??o
de los coeficientes est?? en miles de d??lares?
- ??Cu??l es el valor mediano de las casas en el conjunto de entrenamiento (y)? ??Los
efectos del inciso anterior te parecen razonables?



